{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "53bffd0a",
   "metadata": {},
   "source": [
    "# Run OCR Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0350d00",
   "metadata": {},
   "source": [
    "## Init\n",
    "define here all constant variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c450eb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys_path = r'C:\\Users\\sgala\\PycharmProjects\\OCR\\OCR' # path to project\n",
    "path_to_tesstrain_code = r\"C:/Users/sgala/Documents/python_projects/tesseract/tesstrain\" #download from https://github.com/tesseract-ocr/tesstrain/tree/main and follow instructions\n",
    "#recomended - watch: https://www.youtube.com/watch?v=SvhoBT-PnME&ab_channel=SL7Tech\n",
    "relative_path_to_starting_model = '../tessdata/' #default tesstrain data folder\n",
    "tesseract_exe_path = r\"C:\\Program Files\\Tesseract-OCR\\tesseract.exe\" #install tesseract from: https://github.com/UB-Mannheim/tesseract/wiki\n",
    "tessdata_path = r\"C:\\Program Files\\Tesseract-OCR\\tessdata\\script\" #in tesseract folder after install\n",
    "bash_path = r\"C:/Program Files/Git/bin/bash.exe\" #path to a bash on your computer (problem in windows mostly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19861861",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "import sys\n",
    "sys.path += [sys_path]\n",
    "from generate_pdfs.create_pdf_dataset import create_pdf_dataset\n",
    "from tesseract.prepare_train_data import pdf_to_train_images\n",
    "from tesseract.prepare_validation_data import process_pdf_to_images_and_data\n",
    "from tesseract.metrics import evaluate_ocr_batch\n",
    "from tesseract.match_gt_pred import match_predictions_to_gt\n",
    "import pytesseract\n",
    "import pandas as pd\n",
    "import os\n",
    "import cv2\n",
    "import subprocess\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "pytesseract.pytesseract.tesseract_cmd = tesseract_exe_path\n",
    "os.environ[\"TESSDATA_PREFIX\"] = tessdata_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bac6a696",
   "metadata": {},
   "source": [
    "## Pipeline config\n",
    "    define all the pipeline parameters:\n",
    "    for every stage - weather to do that stage and also all its parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "853604bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_pdfs = False\n",
    "pdfs_dir = r\"C:\\Users\\sgala\\OCR\\pipeline_2\\random_pdfs\"\n",
    "corpus_path = os.path.join(sys_path,\"generate_pdfs\",\"top_500_words.csv\")\n",
    "n_files = 100\n",
    "train_eval_ratio = 0.9\n",
    "prepare_train_data = False\n",
    "train_data_dir = r\"C:\\Users\\sgala\\OCR\\pipeline_2\\train_dataset\"\n",
    "augment = False\n",
    "prepare_eval_data = False\n",
    "eval_data_dir = r\"C:\\Users\\sgala\\OCR\\pipeline_2\\eval_dataset\"\n",
    "train_model = False\n",
    "model_name = \"heb_random_top_five_hundred_two\" #apperently cannot contain numbers, go figure\n",
    "model_dir = r\"C:\\Users\\sgala\\OCR\\pipeline_2\"\n",
    "\n",
    "eval_model = True\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ca11249",
   "metadata": {},
   "source": [
    "## Generate pdfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "980b3b39",
   "metadata": {},
   "outputs": [],
   "source": [
    "if generate_pdfs:\n",
    "    create_pdf_dataset(pdfs_path=pdfs_dir,\n",
    "                       corpus_path=corpus_path,\n",
    "                       n_files=n_files)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03e54854",
   "metadata": {},
   "source": [
    "## Prepare train eval data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f39f1247",
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "if prepare_train_data or prepare_eval_data:\n",
    "    all_paths = glob(pdfs_dir+\"\\*.pdf\")\n",
    "    ratio_index = int(len(all_paths)*train_eval_ratio)\n",
    "    train_paths = all_paths[:ratio_index]\n",
    "    eval_paths = all_paths[ratio_index:]\n",
    "\n",
    "    for tp in train_paths:\n",
    "        pdf_to_train_images(tp, train_data_dir, augment=augment) #dpi?\n",
    "    for ep in eval_paths:\n",
    "        process_pdf_to_images_and_data(ep, output_dir=eval_data_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6bdecac",
   "metadata": {},
   "source": [
    "## train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa5bee92",
   "metadata": {},
   "source": [
    "Training is a bit finecy due to workign with makefile - this is the best i managed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b19f9eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "if train_model:\n",
    "    #moving folders to default locations in tesstrain\n",
    "    train_folder_location = os.path.join(path_to_tesstrain_code,'data',f\"{model_name}-ground-truth\")\n",
    "    shutil.move(train_data_dir, train_folder_location)\n",
    "    #creating makefile commands to run on bash\n",
    "    make_command = f\"make -C {path_to_tesstrain_code} training MODEL_NAME={model_name} START_MODEL=heb_best TESSDATA={relative_path_to_starting_model} MAX_ITERATIONS=2000 LANG_TYPE=RTL --debug\"\n",
    "    make_command_2 = f\"make -C {path_to_tesstrain_code} traineddata MODEL_NAME={model_name} --debug\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cace5a7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if train_model:\n",
    "    print(\"the next block will try to run these commands:\")\n",
    "    print(make_command)\n",
    "    print(make_command_2)\n",
    "    print(\"if this doesnt work - please open bash and run it manually\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8529214c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if train_model:\n",
    "    process = subprocess.Popen([bash_path, \"-c\", make_command], stdout=subprocess.PIPE, shell=False)\n",
    "    for line in process.stdout:\n",
    "        print(line.decode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e01e700",
   "metadata": {},
   "outputs": [],
   "source": [
    "if train_model:\n",
    "    #moving folders back to pipeline folder\n",
    "    shutil.move(train_folder_location, train_data_dir)\n",
    "    trained_model_folder = os.path.join(path_to_tesstrain_code,'data',f\"{model_name}\")\n",
    "    trained_model_folder_new = os.path.join(model_dir,model_name)\n",
    "    shutil.move(trained_model_folder,trained_model_folder_new)\n",
    "    #moving best model to models folder in tesseract folder\n",
    "    models_path = glob(os.path.join(trained_model_folder_new,\"tessdata_best\",\"*.traineddata\"))\n",
    "    performence = np.array([float(model_path.split(\"_\")[-3]) for model_path in models_path])\n",
    "    best_model_path = models_path[np.argmin(performence)]\n",
    "    shutil.copy(best_model_path,os.path.join(tessdata_path,f\"{model_name}.traineddata\") )\n",
    "    print(\"model name should be here:\")\n",
    "    print(pytesseract.get_languages())\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ff52dc5",
   "metadata": {},
   "source": [
    "## Eval model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2cfc46f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageDraw, ImageFont\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "#TODO: move to seperate file\n",
    "def visualize_ocr_utf8(image, bboxes, words,wers, font_path=\"arial.ttf\", font_size=20, right_box_color=(0, 255, 0), wrong_box_color=(255, 0, 0), text_color=(10, 10, 10), thickness=2):\n",
    "    \"\"\"\n",
    "    Visualizes OCR results with support for UTF-8 characters.\n",
    "\n",
    "    Parameters:\n",
    "        image (numpy.ndarray): The image (read via OpenCV).\n",
    "        bboxes (list of list of int): List of bounding boxes, where each box is [x1, y1, x2, y2].\n",
    "        words (list of str): List of words corresponding to each bounding box.\n",
    "        font_path (str): Path to a TrueType font file (supports UTF-8 characters).\n",
    "        font_size (int): Font size for the text.\n",
    "        right_box_color (tuple): Color of the bounding box (default is green).\n",
    "        right_box_color (tuple): Color of the bounding box if the prediction is wrong(default is red).\n",
    "        text_color (tuple): Color of the text (default is black).\n",
    "        thickness (int): Thickness of the bounding box.\n",
    "\n",
    "    Returns:\n",
    "        None: Displays the image with OCR annotations.\n",
    "    \"\"\"\n",
    "    # Convert the image to a PIL image\n",
    "    pil_image = Image.fromarray(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "    draw = ImageDraw.Draw(pil_image)\n",
    "    \n",
    "    # Load the specified font\n",
    "    try:\n",
    "        font = ImageFont.truetype(font_path, font_size)\n",
    "    except IOError:\n",
    "        raise IOError(f\"Font not found at {font_path}. Please specify a valid TrueType font file.\")\n",
    "    \n",
    "    # Draw bounding boxes and text\n",
    "    for bbox, word,wer in zip(bboxes, words,wers):\n",
    "        if not bbox:\n",
    "            continue\n",
    "        x1, y1, x2, y2 = bbox  # Unpack the bounding box\n",
    "        \n",
    "        bbox_color = right_box_color if (wer is not None) and (wer<=0) else wrong_box_color\n",
    "        # Draw the bounding box\n",
    "        draw.rectangle([x1, y1, x2, y2], outline=bbox_color, width=thickness)\n",
    "        \n",
    "        # Add the text above the bounding box\n",
    "        draw.text((x1, y1 - font_size), word[::-1], fill=text_color, font=font)\n",
    "    \n",
    "    # Convert back to OpenCV format for displaying with Matplotlib\n",
    "    result_image = np.array(pil_image)\n",
    "    return result_image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e697d14",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import os.path as osp\n",
    "import json\n",
    "if eval_model:\n",
    "    results = []\n",
    "    verbose=True\n",
    "    for p in glob(osp.join(eval_data_dir,'*output_data.json')):\n",
    "        with open(p, encoding=\"utf-8\") as f:\n",
    "            document_data = json.load(f)\n",
    "            for page, page_data in document_data.items():\n",
    "                image_data_pred = pytesseract.image_to_data(page_data['image_path'],output_type=pytesseract.Output.DICT,lang=model_name)\n",
    "                image_data_pred = pd.DataFrame(image_data_pred)\n",
    "                image_data_pred['bbox'] = image_data_pred.apply(lambda r: (r['left'],r['top'],r['left'] + r['width'] ,r['top'] + r['height']),axis=1)\n",
    "                image_data_pred  = image_data_pred[image_data_pred['conf']!=-1]\n",
    "                gt_bbox = page_data['bboxes']\n",
    "                gt_text = page_data['words']\n",
    "                pred_bbox = list(image_data_pred['bbox'])\n",
    "                pred_text = list(image_data_pred['text'])\n",
    "                pred_conf = list(image_data_pred['conf'])\n",
    "                \n",
    "                try:\n",
    "                    pred_text, pred_bbox, gt_text, gt_bbox, pred_conf, eval_stats = match_predictions_to_gt(pred_text,\n",
    "                                                                                                      pred_bbox,\n",
    "                                                                                                      gt_text,\n",
    "                                                                                                      gt_bbox,\n",
    "                                                                                                      pred_conf,\n",
    "                                                                                                      intersect_threshold=0.8)\n",
    "                    batch_results = evaluate_ocr_batch(pred_text, gt_text, pred_bbox, gt_bbox, pred_conf)\n",
    "                    for k,v in eval_stats.items():\n",
    "                        batch_results[k] = v\n",
    "                except Exception as e:\n",
    "                    print(e)\n",
    "                    continue\n",
    "                results.append(batch_results)\n",
    "                if verbose:\n",
    "                    image = cv2.imread(page_data['image_path'])\n",
    "                    img_rgb = visualize_ocr_utf8(image, pred_bbox, pred_text,wers = batch_results['WERs'],font_size=40)\n",
    "                    # Display the image\n",
    "                    plt.figure(figsize=(24, 16))\n",
    "                    plt.imshow(img_rgb)\n",
    "                    plt.axis('off')\n",
    "                    plt.show()\n",
    "\n",
    "    results = pd.DataFrame(results)\n",
    "    results['word_count'] = results['WERs'].apply(lambda x: len(x))\n",
    "    stats = results[[c for c in results.columns if \"Avg\" in c or c=='word_count']]\n",
    "    stats = stats.multiply(stats['word_count'],axis=0).sum()/stats['word_count'].sum()\n",
    "    for k in eval_stats.keys():\n",
    "        stats[f\"Total_{k}\"] = results[k].sum()\n",
    "    col_order = [c for c in stats.index if \"Total\" in c] + [c for c in stats.index if \"Avg\" in c]\n",
    "    stats = stats[col_order]\n",
    "\n",
    "    print(stats)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
